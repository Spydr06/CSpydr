#define LEXER_TESTS                             \
    {"lexing symbols", test_lexer_symbols},     \
    {"lexing strings", test_lexer_strings},     \
    {"lexing numbers", test_lexer_numbers},     \
    {"lexing ids", test_lexer_ids},             \
    {"lexing keywords", test_lexer_keywords}

void test_lexer_symbols(void)
{
    SrcFile_T* file = get_file(1, "{}()[];:,+-*/ =! != == >= <=");
    TEST_ASSERT(file != NULL);

    ErrorHandler_T* eh = init_errorhandler();
    TEST_ASSERT(eh != NULL);

    Lexer_T* lexer = init_lexer(file, eh);
    TEST_ASSERT(lexer != NULL);

#define NUM_TOKENS 19
    char* expectedTokens[NUM_TOKENS] = {
        "{", "}", "(", ")", "[", "]",
        ";", ":", ",",
        "+", "-", "*", "/", "=", "!",
        "!=", "==", ">=", "<="
    };
    
    for(int i = 0; i < NUM_TOKENS; i++)
    {
        Token_T* token =  lexer_next_token(lexer);
        TEST_ASSERT(token != NULL);

        TEST_ASSERT(token->value != NULL);
        TEST_CHECK(strcmp(token->value, expectedTokens[i]) == 0);
    }
#undef NUM_TOKENS
}

void test_lexer_strings(void)
{
    SrcFile_T* file = get_file(4, "\"hello\"\n", "\"\n", "world\n", "\"\n");
    TEST_ASSERT(file != NULL);

    ErrorHandler_T* eh = init_errorhandler();
    TEST_ASSERT(eh != NULL);

    Lexer_T* lexer = init_lexer(file, eh);
    TEST_ASSERT(lexer != NULL);

#define NUM_TOKENS 2
    char* expectedTokens[NUM_TOKENS] = {
        "hello", "\nworld\n"
    };

    for(int i = 0; i < NUM_TOKENS; i++)
    {
        Token_T* token =  lexer_next_token(lexer);
        TEST_ASSERT(token != NULL);
        TEST_CHECK(token->type == TOKEN_STRING);

        TEST_ASSERT(token->value != NULL);
        TEST_CHECK(strcmp(token->value, expectedTokens[i]) == 0);
    }
#undef NUM_TOKENS
}

void test_lexer_numbers(void)
{
    SrcFile_T* file = get_file(1, "23 2.5 0b0101 0xff 100_000_000");
    TEST_ASSERT(file != NULL);

    ErrorHandler_T* eh = init_errorhandler();
    TEST_ASSERT(eh != NULL);

    Lexer_T* lexer = init_lexer(file, eh);
    TEST_ASSERT(lexer != NULL);

#define NUM_TOKENS 5
    char* expectedTokens[NUM_TOKENS] = {
        "23", "2.5", "5", "255", "100000000"
    };

    for(int i = 0; i < NUM_TOKENS; i++)
    {
        Token_T* token =  lexer_next_token(lexer);
        TEST_ASSERT(token != NULL);
        TEST_CHECK(token->type == TOKEN_INT || token->type == TOKEN_FLOAT);

        TEST_ASSERT(token->value != NULL);
        TEST_CHECK(strcmp(token->value, expectedTokens[i]) == 0);
    }
#undef NUM_TOKENS
}

void test_lexer_ids(void)
{
    SrcFile_T* file = get_file(2, "hello wor\n", "ld");
    TEST_ASSERT(file != NULL);

    ErrorHandler_T* eh = init_errorhandler();
    TEST_ASSERT(eh != NULL);

    Lexer_T* lexer = init_lexer(file, eh);
    TEST_ASSERT(lexer != NULL);

#define NUM_TOKENS 3
    char* expectedTokens[NUM_TOKENS] = {
        "hello", "wor", "ld"
    };

    for(int i = 0; i < NUM_TOKENS; i++)
    {
        Token_T* token =  lexer_next_token(lexer);
        TEST_ASSERT(token != NULL);
        TEST_CHECK(token->type == TOKEN_ID);

        TEST_ASSERT(token->value != NULL);
        TEST_CHECK(strcmp(token->value, expectedTokens[i]) == 0);
    }
#undef NUM_TOKENS
}

void test_lexer_keywords(void)
{
    SrcFile_T* file = get_file(1, "true false nil let fn loop if else ret match type struct enum import");
    TEST_ASSERT(file != NULL);

    ErrorHandler_T* eh = init_errorhandler();
    TEST_ASSERT(eh != NULL);

    Lexer_T* lexer = init_lexer(file, eh);
    TEST_ASSERT(lexer != NULL);

#define NUM_TOKENS 14
    TokenType_T expectedTokens[NUM_TOKENS] = {
        TOKEN_TRUE, TOKEN_FALSE, TOKEN_NIL, TOKEN_LET, TOKEN_FN, TOKEN_LOOP, TOKEN_IF, TOKEN_ELSE, TOKEN_RETURN, TOKEN_MATCH, TOKEN_TYPE, TOKEN_STRUCT, TOKEN_ENUM, TOKEN_IMPORT
    };

    for(int i = 0; i < NUM_TOKENS; i++)
    {
        Token_T* token =  lexer_next_token(lexer);
        TEST_ASSERT(token != NULL);
        TEST_CHECK(token->type == expectedTokens[i]);

        TEST_ASSERT(token->value != NULL);
    }
#undef NUM_TOKENS
}
